{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Importing Packages"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Loading Files"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_df=pd.read_csv('../input/santander-customer-satisfaction/train.csv').set_index('ID')\ntest_df=pd.read_csv('../input/santander-customer-satisfaction/test.csv').set_index('ID')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> ### Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" \n    iterate through all the columns of a dataframe and \n    modify the data type to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print(('Memory usage of dataframe is {:.2f}''MB').format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max <np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max <np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max <np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max <np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                #if c_min > np.finfo(np.float16).min and c_max <np.finfo(np.float16).max:\n                    #df[col] = df[col].astype(np.float16)\n                if c_min > np.finfo(np.float32).min and c_max <np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n    end_mem = df.memory_usage().sum() / 1024**2\n    print(('Memory usage after optimization is: {:.2f}''MB').format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reducing memory\ntrain_df=reduce_mem_usage(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Custom Code to Display properties of each column\nl=[]\nfor i in train_df.columns:\n    l.append([i,len(train_df[i].unique()),max(train_df[i].unique()),min(train_df[i].unique()),train_df[i].var(),train_df[i].astype(bool).sum(axis=0),train_df[i].count(),list(train_df[i].unique())])\nldf=pd.DataFrame(l, columns=['Features', 'No_Unique_Values', 'Max_Value','Min_Value','Variance','Non-Zero','Total_Values','Unique_Values'])\nldf.head(307)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (sorted(ldf['No_Unique_Values'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ldf[ldf['Non-Zero']<10000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del_features=list(ldf[ldf.No_Unique_Values==1].Features)\nldf[ldf.No_Unique_Values==1].shape\n#Remove these Columns : No Unique Value - 34 Columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_impute=list(ldf[ldf.Max_Value==9999999999].Features)\nfor i in max_impute:\n    if i in train_df.columns:\n        print (train_df[train_df[i]==9999999999].shape,'\\t',i)\n    else:\n        print ('Column Removed')\n#missing values in max_impute Columns - 307 rows each - Impute the values - Use median\n#max_impute","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"min_impute=list(ldf[ldf.Min_Value==-999999.00].Features)\nfor i in min_impute:\n    if i in train_df.columns:\n        print (train_df[train_df[i]==-999999.00].shape,'\\t',i)\n    else:\n        print ('Column Removed')\n#missing values in max_impute Columns - 307 rows each - Impute the values - Use median\n#min_impute","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#replacing missing values\ntrain_df.replace({9999999999:np.NaN,-999999:np.NaN},inplace=True)\ntrain_df.fillna(train_df.median(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del_ID=list(train_df[train_df.duplicated()==True].index)\ntrain_df[train_df.duplicated()==True].shape\n#Duplicated Records - To be removed - 4807 rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns=list(train_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fea_del_set=set()\nfor i in range(len(columns)):\n    for j in range(i+1,len(columns)):\n        if train_df[columns[i]].equals(train_df[columns[j]]) and columns[j] not in fea_del_set:\n            fea_del_set.add(columns[j])\n#62 Columns        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Double Check\n\"\"\"fea_del={}\nfor i in range(len(columns)):\n    l=[]\n    for j in range(i+1,len(columns)):\n        if train_df[columns[i]].equals(train_df[columns[j]]):\n            l.append(columns[j])\n    if l!=[]:\n        fea_del[columns[i]]=l\n##Check accuracy\nset1=set()\nfor i in list(fea_del.values()):\n    for j in i:\n        set1.add(j)\nassert len(set1)==len(fea_del_set)\"\"\"\npass       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del_col=fea_del_set.union(del_features)\n#63 columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#del_col\n\"\"\"\n{'delta_num_reemb_var13_1y3',\n 'delta_num_reemb_var17_1y3',\n 'delta_num_reemb_var33_1y3',\n 'delta_num_trasp_var17_in_1y3',\n 'delta_num_trasp_var17_out_1y3',\n 'delta_num_trasp_var33_in_1y3',\n 'delta_num_trasp_var33_out_1y3',\n 'imp_amort_var18_hace3',\n 'imp_amort_var34_hace3',\n 'imp_reemb_var13_hace3',\n 'imp_reemb_var33_hace3',\n 'imp_trasp_var17_out_hace3',\n 'imp_trasp_var33_out_hace3',\n 'ind_var13_medio',\n 'ind_var18',\n 'ind_var2',\n 'ind_var25',\n 'ind_var26',\n 'ind_var27',\n 'ind_var27_0',\n 'ind_var28',\n 'ind_var28_0',\n 'ind_var29',\n 'ind_var29_0',\n 'ind_var2_0',\n 'ind_var32',\n 'ind_var34',\n 'ind_var37',\n 'ind_var39',\n 'ind_var41',\n 'ind_var46',\n 'ind_var46_0',\n 'num_reemb_var13_hace3',\n 'num_reemb_var33_hace3',\n 'num_trasp_var17_out_hace3',\n 'num_trasp_var33_out_hace3',\n 'num_var13_medio',\n 'num_var18',\n 'num_var25',\n 'num_var26',\n 'num_var27',\n 'num_var27_0',\n 'num_var28',\n 'num_var28_0',\n 'num_var29',\n 'num_var29_0',\n 'num_var2_0_ult1',\n 'num_var2_ult1',\n 'num_var32',\n 'num_var34',\n 'num_var37',\n 'num_var39',\n 'num_var41',\n 'num_var46',\n 'num_var46_0',\n 'saldo_medio_var13_medio_hace3',\n 'saldo_medio_var13_medio_ult1',\n 'saldo_var27',\n 'saldo_var28',\n 'saldo_var29',\n 'saldo_var2_ult1',\n 'saldo_var41',\n 'saldo_var46'}\n\"\"\"\nlen(del_col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop(del_col, axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.drop_duplicates(keep='first',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_u2=list(ldf[ldf.No_Unique_Values==2].Features)\nf_u3=list(ldf[ldf.No_Unique_Values==3].Features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unique_percent(df,column):\n    unique=list(df[column].unique())\n    total=df[column].count()\n    count=[]\n    percent=[]\n    for i in unique:\n        count.append((i,(df[column]==i).sum()))\n        percent.append((i,(df[column]==i).sum()/total*100))\n    return count,percent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count=[]\npercent=[]\nfor i in f_u2:\n    c,p=unique_percent(train_df,i)\n    count.append((i,c))\n    percent.append((i,p))\ncount","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count=[]\npercent=[]\nfor i in f_u3:\n    c,p=unique_percent(train_df,i)\n    count.append((i,c))\n    percent.append((i,p))\npercent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[train_df.num_reemb_var17_hace3==3]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}